---

generated_by: doc-testing

---



# vs Cap'n Web (performance)

<details>
<summary><strong>ðŸ“˜ Doc-testing</strong> â€“ Why do these examples look like tests?</summary>

This documentation uses **testable code examples** to ensure accuracy and reliability:

- **Guaranteed accuracy**: All examples are real, working code that runs against the actual library
- **Always up-to-date**: When the library changes, the tests fail and the docs must be updated
- **Copy-paste confidence**: What you see is what works - no outdated or broken examples
- **Real-world patterns**: Tests show complete, runnable scenarios, not just snippets

Ignore the test boilerplate (`it()`, `describe()`, etc.) - focus on the code inside.

</details>

This living documentation compares performance characteristics between Lumenize 
RPC and Cap'n Web (Cloudflare's official "last-mile" RPC solution).

**Bottom line**: The performance differences between Cap'n Web and Lumenize RPC 
are essentially zero for the common use cases (reciepts below).

## Imports




```typescript test
import { it, expect } from 'vitest';
// @ts-expect-error - cloudflare:test module types are not consistently exported
import { SELF } from 'cloudflare:test';
import { createRpcClient, getWebSocketShim } from '@lumenize/rpc';
import { newWebSocketRpcSession } from 'capnweb';
import type { Metrics } from '@lumenize/utils';

import { LumenizeDO, CapnWebRpcTarget } from '../src/index';
```




## Version(s)

This test asserts the installed version(s) and our release script warns if we 
aren't using the latest version published to npm, so this living documentation 
should always be up to date.

Using this doc-test approach, when either package changes its implementation, 
we'll know immediately because the tests will start failing.




```typescript test
import lumenizeRpcPackage from '../../../../packages/rpc/package.json';
import capnwebPackage from '../../../../node_modules/capnweb/package.json';
it('detects package versions', () => {
  expect(lumenizeRpcPackage.version).toBe('0.10.0');
  expect(capnwebPackage.version).toBe('0.1.0');
});
```




## Creating Clients




```typescript test
function getLumenizeClient(instanceName: string, metrics?: Metrics) {
  return createRpcClient<typeof LumenizeDO>(
    'LUMENIZE',
    instanceName,
    { WebSocketClass: getWebSocketShim(SELF.fetch.bind(SELF), { metrics }) }
  );
}

function getCapnWebClient(instanceName: string, metrics?: Metrics) {
  const url = `wss://test.com/capnweb/capnweb/${instanceName}`;
  const ws = new (getWebSocketShim(SELF.fetch.bind(SELF), { metrics }))(url);
  return newWebSocketRpcSession<CapnWebRpcTarget>(ws);
}
```




## Metrics Setup




```typescript test
let lumenizeMetrics: Metrics = {};
let capnwebMetrics: Metrics = {};
```




## Automatic Batching

Automatic batching allows multiple RPC calls to be sent together without waiting
for each response. This can significantly reduce round trips when making
multiple calls in sequence, and as we said, round trip count determines
essentially the entire performance story with a "remote" procedure calling
system.

**Key insight:** For this simple case, there is no difference between Cap'n Web 
and Lumenize RPC with respect to round trip count. Cap'n Web is much more
chatty on the outgoing message count (5 for Cap'n Web vs 1 for Lumenize RPC).

However, that's a distinction without a difference when using WebSockets which 
will push them all out over the wire simultaneously. The only metrics here that 
matter are the received message counts and the count of WebSocket upgrade 
requests, which do represent another round trip.

**Cap'n Web and Lumenize RPC have identical round trip counts (2 each).**




```typescript test
it('compares round trips when using automatic batching', async () => {
  // ==========================================================================
  // Lumenize RPC - automatic batching
  // ==========================================================================
  using lumenizeClient = getLumenizeClient('pipeline', lumenizeMetrics);
  lumenizeClient.increment();  // Returns promise, not awaited
  lumenizeClient.increment();  // Returns promise, not awaited
  const lumenizeResult = await lumenizeClient.increment();  // Await final result

  // ==========================================================================
  // Cap'n Web - automatic batching
  // ==========================================================================
  using capnwebClient = getCapnWebClient('pipeline', capnwebMetrics);
  capnwebClient.increment();  // Returns promise, not awaited
  capnwebClient.increment();  // Returns promise, not awaited
  const capnwebResult = await capnwebClient.increment();  // Await final result

  // Both should produce the same final result
  expect(lumenizeResult).toBe(3);
  expect(capnwebResult).toBe(3);

  // Both create exactly one WebSocket connection
  expect(lumenizeMetrics.wsUpgradeRequests).toBe(1);
  expect(capnwebMetrics.wsUpgradeRequests).toBe(1);

  // --- Message batching comparison ---
  
  // Lumenize batches all calls into one message and gets back one message
  expect(lumenizeMetrics.wsSentMessages).toBe(1);
  expect(lumenizeMetrics.wsReceivedMessages).toBe(1);
  
  // Cap'n Web sends information about each call plus some handshake in 
  // seperate messages, but that doesn't matter because it too only needs one 
  // response message.
  expect(capnwebMetrics.wsSentMessages).toBe(5);  // Handshake + calls
  expect(capnwebMetrics.wsReceivedMessages).toBe(1);  // Batched response
});
```




## Payload byte count (small payloads)

Let's compare the byte counts for the payloads for the above calls.

**Key insight:** For this simple case, the bytes needed to achieve
[Lumenize RPC's greater type support](/docs/rpc/capn-web-comparison-basics-and-types#supported-types)
(cycles/aliases, Set, Map, etc.)
results in it needing 4.6x the byte count.

However, just like Cap'n Web's 5x messages sent count disadvantage in the test 
above, this is also a distinction without much of a difference. The latency
impact of this 577 byte difference at even a very slow connection of say 10Mb/s 
is 0.46ms (0.00046 seconds) and more importantly, the payloads are so small
that all we are measuring is framing.




```typescript test
it('compares byte count (small payloads)', async () => {
  // --- Payload bytes sent ----
  // Lumenize sends more bytes because it uses JSON-RPC
  // vs Cap'n Web's binary Cap'n Proto protocol
  // Note: Batch format adds wrapper overhead but enables pipelining
  expect(lumenizeMetrics.wsSentPayloadBytes).toBeCloseTo(460, -1);
  expect(capnwebMetrics.wsSentPayloadBytes).toBeCloseTo(145, -1);
  
  // --- Payload bytes received ---
  // Response sizes - Cap'n Web is much more compact
  // Note: Batch format adds wrapper overhead but enables pipelining
  expect(lumenizeMetrics.wsReceivedPayloadBytes).toBeCloseTo(277, -1);
  expect(capnwebMetrics.wsReceivedPayloadBytes).toBeCloseTo(15, -1);
});
```




## Payload byte count (larger payloads)

The previous test showed a 4.6x overhead for Lumenize RPC, but that's mostly
framing overhead on tiny payloads. Let's test with a more realistic payload
size - a 10KB string, which is not very large and would still travel over a very slow 10Mb/s in ~8ms.

**Key insight:** With actual data payloads, the framing overhead becomes
negligible. Lumenize RPC is only 1.6% larger which translates to an additional
0.27ms (0.00027 seconds) of latency over a very slow 10Mb/s connection.




```typescript test
it('compares byte count with 10KB payload', async () => {
  // Create a 10KB string (10,240 characters)
  const largeString = 'x'.repeat(10240);
  
  // Reset metrics for this test
  const lumenizeLgMetrics: Metrics = {};
  const capnwebLgMetrics: Metrics = {};
  
  // ==========================================================================
  // Lumenize RPC
  // ==========================================================================
  using lumenizeClient = getLumenizeClient('large-payload', lumenizeLgMetrics);
  await lumenizeClient.echo(largeString);
  
  // ==========================================================================
  // Cap'n Web
  // ==========================================================================
  using capnwebClient = getCapnWebClient('large-payload', capnwebLgMetrics);
  await (capnwebClient as any).echo(largeString);
  
  // Calculate total bytes (sent + received)
  const lumenizeTotal = 
    lumenizeLgMetrics.wsSentPayloadBytes + 
    lumenizeLgMetrics.wsReceivedPayloadBytes;
  const capnwebTotal = 
    capnwebLgMetrics.wsSentPayloadBytes + 
    capnwebLgMetrics.wsReceivedPayloadBytes;
  
  // Ratio: 1.016 (Lumenize 1.6% larger)
  const totalRatio = lumenizeTotal / capnwebTotal;
  expect(totalRatio).toBeCloseTo(1.016, 2);
});
```




## HTTP Batching

Here we demonstrate that Lumenize RPC passively batches over HTTP so it needs
only one round trip per batch.

The Cap'n Web `newHttpBatchRpcSession()` is not shown in this doc-test
We may verify this experimentally at a later date, but for now we assume it 
uses exactly one round trip, like Lumenize RPC.

**Key insight:** Lumenize RPC and Cap'n Web both use one round trip over HTTP.
However, the DX advantage of Lumenize RPC is clear: client and server require 
no code changes to switch between transports, just change the transport option 
to 'http'.




```typescript test
it('demonstrates HTTP batching in Lumenize RPC', async () => {
  const metrics: Metrics = {};
  
  // ==========================================================================
  // Lumenize RPC - HTTP transport (same DO as WebSocket examples above)
  // ==========================================================================
  using client = createRpcClient<typeof LumenizeDO>(
    'LUMENIZE',
    'http-batch-demo',
    { 
      transport: 'http',  // Only difference from WebSocket!
      fetch: (input, init) => {
        metrics.httpRequests = (metrics.httpRequests ?? 0) + 1;
        metrics.roundTrips = (metrics.roundTrips ?? 0) + 1;
        return SELF.fetch(input, init);
      }
    }
  );
  
  // Fire 3 operations - automatically batched into 1 HTTP request
  client.increment();
  client.increment();
  const result = await client.increment();
  
  expect(result).toBe(3);
  
  // All 3 operations sent in exactly 1 HTTP request
  expect(metrics.roundTrips).toBe(1);
});
```




## Promise Pipelining

Cap'n Web supports true promise pipelining where you can use the result of an 
unawaited call as a parameter to another call. This creates dependent operations
that can still be done with a single round trip because the server resolves the 
promise values.

Lumenize RPC does not currently support this feature - it only supports 
automatic batching of independent operations.

**Key insight:** All three calls happen in one round trip because Cap'n Web
substitutes the promise values on the server side.




```typescript test
it('demonstrates true promise pipelining (Cap\'n Web only)', async () => {
  const metrics: Metrics = {};
  
  // ==========================================================================
  // Cap'n Web - True promise pipelining with dependent operations
  // ==========================================================================
  using client = getCapnWebClient('geometric-progression', metrics);
  
  // Geometric progression using promise pipelining:
  const firstResult = client.increment();  // increment() â†’ 1
  const secondResult = client.increment(firstResult);  // increment(1) â†’ 2
  const finalResult = await client.increment(secondResult);  // increment(2) â†’ 4
  
  // Final result should be 4 (geometric progression: 1 â†’ 2 â†’ 4)
  expect(finalResult).toBe(4);
  
  // All 3 dependent operations sent in exactly 1 round trip!
  expect(metrics.wsUpgradeRequests).toBe(1);
  expect(metrics.wsReceivedMessages).toBe(1);
});
```




## Installation

```bash npm2yarn
npm install --save-dev vitest@3.2
npm install --save-dev @vitest/coverage-istanbul@3.2
npm install --save-dev @cloudflare/vitest-pool-workers
npm install --save-dev @lumenize/rpc
npm install --save-dev @lumenize/utils
npm install --save-dev capnweb
```

## Configuration Files

### src/index.ts

Worker, DurableObjects and RpcTargets

```typescript src/index.ts
import { DurableObject, RpcTarget } from 'cloudflare:workers';
import { lumenizeRpcDO } from '@lumenize/rpc';
import { routeDORequest } from '@lumenize/utils';
import { newWorkersRpcResponse } from 'capnweb';

// ============================================================================
// Lumenize RPC
// ============================================================================

class _LumenizeDO extends DurableObject {
  increment(count: number = 1): number {
    let currentCount = (this.ctx.storage.kv.get<number>("count")) ?? 0;
    currentCount += count;
    this.ctx.storage.kv.put("count", currentCount);
    return currentCount;
  }

  echo(value: any): any {
    return value;
  }
}

export const LumenizeDO = lumenizeRpcDO(_LumenizeDO);

// ============================================================================
// Cap'n Web - A little more boilerplate (fetch and constructor, but the latter
//             is only because we want to use storage and test env access)
// ============================================================================

// Per Cap'n Web docs: "Classes which are intended to be passed by reference 
// and called over RPC must extend RpcTarget"
export class CapnWebRpcTarget extends RpcTarget {
  // RpcTarget requires us to manually capture ctx/env in constructor
  constructor(
    public ctx: DurableObjectState,
    public env: any
  ) {
    super();
  }
  
  increment(count: number = 1): number {
    let currentCount = (this.ctx.storage.kv.get<number>("count")) ?? 0;
    currentCount += count;
    this.ctx.storage.kv.put("count", currentCount);
    return currentCount;
  }

  echo(value: any): any {
    return value;
  }

  fetch(request: Request): Response | Promise<Response> {
    return newWorkersRpcResponse(request, this);
  }
}

// ============================================================================
// Worker - Route requests to appropriate DO
// ============================================================================

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const lumenizeResponse = await routeDORequest(request, env, { prefix: '__rpc' });
    if (lumenizeResponse) return lumenizeResponse;
    
    const capnwebResponse = await routeDORequest(request, env, { prefix: 'capnweb' });
    if (capnwebResponse) return capnwebResponse;

    // Fallback for non-RPC requests
    return new Response('Not found', { status: 404 });
  },
};

```

### wrangler.jsonc

```json wrangler.jsonc
{
  "name": "feature-comparison",
  "main": "src/index.ts",
  "compatibility_date": "2025-09-12",
  "durable_objects": {
    "bindings": [
      {
        "name": "LUMENIZE",
        "class_name": "LumenizeDO"
      },
      {
        "name": "CAPNWEB",
        "class_name": "CapnWebRpcTarget"
      }
    ]
  },
  "migrations": [
    {
      "tag": "v1",
      "new_sqlite_classes": ["LumenizeDO", "CapnWebRpcTarget"]
    }
  ]
}

```

### vitest.config.js

```javascript vitest.config.js
import { defineWorkersProject } from "@cloudflare/vitest-pool-workers/config";

export default defineWorkersProject({
  test: {
    testTimeout: 2000, // 2 second global timeout
    poolOptions: {
      workers: {
        // Must be false to use websockets. Have each test
        // reference a different DO instance to avoid state sharing.
        isolatedStorage: false,
        // Important! use the wrangler.jsonc in ./test
        wrangler: { configPath: "./wrangler.jsonc" },  
      },
    },
    // Use `vitest --run --coverage` to get test coverage report(s)
    coverage: {
      provider: "istanbul",  // Cannot use V8
      reporter: ['text', 'json', 'html'],
      include: ['**/src/**'],
      exclude: [
        '**/node_modules/**', 
        '**/dist/**', 
        '**/build/**', 
        '**/*.config.ts',
        '**/scratch/**'
      ],
    },
  },
});

```

## Try it out

To run these examples:
```bash
vitest --run
```

To see test coverage:
```bash
vitest --run --coverage
```